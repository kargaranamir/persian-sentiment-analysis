{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Before You Run\n",
        "make a `data` drectory and upload data (eval, test and train csvs)"
      ],
      "metadata": {
        "id": "IDh-HjxqmTcj"
      },
      "id": "IDh-HjxqmTcj"
    },
    {
      "cell_type": "code",
      "source": [
        "# ! mkdir data"
      ],
      "metadata": {
        "id": "PuPsSNI5lZ1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48856119-29a5-46a3-e210-963fb99430ed"
      },
      "id": "PuPsSNI5lZ1Z",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install fasttext\n",
        "! pip install fasttext\n",
        "\n",
        "# install gdown to download fasttext model from google drive (with maximum speed!)\n",
        "! pip install gdown\n",
        "\n",
        "# install matplotlib to prevent unwelcome errors\n",
        "! pip install matplotlib==3.1.3\n",
        "\n",
        "! pip install hazm"
      ],
      "metadata": {
        "id": "DTKXZusSQNl1"
      },
      "id": "DTKXZusSQNl1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "I0YkX5CXepfi"
      },
      "id": "I0YkX5CXepfi"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "07ab578b-d556-407c-a357-77c15b17be3b",
      "metadata": {
        "id": "07ab578b-d556-407c-a357-77c15b17be3b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf \n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout, SpatialDropout1D\n",
        "from tensorflow.keras.layers import GlobalMaxPool1D, MaxPooling1D, GlobalMaxPooling1D, Conv1D\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import fasttext\n",
        "\n",
        "from hazm import word_tokenize, Normalizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "NIvkU8e2eSm3"
      },
      "id": "NIvkU8e2eSm3"
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = 'data/'\n",
        "PATH = PATH.rstrip('/')\n",
        "\n",
        "# Train\n",
        "df_train = pd.read_csv(PATH + '/train.csv')\n",
        "df_train.columns = ['index', 'comment', 'rate']\n",
        "\n",
        "# Evaluation\n",
        "df_eval = pd.read_csv(PATH + '/eval.csv')\n",
        "df_eval.columns = ['index', 'comment', 'rate']\n",
        "\n",
        "# Test\n",
        "df_test = pd.read_csv(PATH + '/test.csv')\n",
        "df_test.columns = ['index', 'comment', 'rate']\n",
        "\n",
        "# Create Lables\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "train_y = label_encoder.fit_transform((df_train['rate'] >= 0).astype(int))\n",
        "eval_y = label_encoder.fit_transform((df_eval['rate'] >= 0).astype(int))\n",
        "test_y = label_encoder.fit_transform((df_test['rate'] >= 0).astype(int))"
      ],
      "metadata": {
        "id": "yBYACIpBxCaa"
      },
      "id": "yBYACIpBxCaa",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess"
      ],
      "metadata": {
        "id": "g3UJaMTV6B9F"
      },
      "id": "g3UJaMTV6B9F"
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = Normalizer() # Hazm normlizer\n",
        "symbols_complete_reg = re.compile(r\"(\\d|\\\"|'ٍ|¬|[؛“،,”‘۔’’‘–]|[|\\.÷+\\]\\[\\)\\(\\:\\-\\?»\\=\\{}\\*«»_…\\؟!/ـ]|[۰'ٓ۫'ٔ]|[ٓٔ]|[ًٌٍْﹼ،َُِّ«ٰ»ٖء])\")\n",
        "\n",
        "def remeove_arabic(text):\n",
        "    # remove arabic alphabet\n",
        "    mapping = {\n",
        "        u\"ۀ\" : u\"ه\",\n",
        "        u\"ة\" : u\"ت\",\n",
        "        u\"ي\" : u\"ی\",\n",
        "        u\"ؤ\" : u\"و\",\n",
        "        u\"إ\" : u\"ا\",\n",
        "        u\"ٹ\" : u\"ت\",\n",
        "        u\"ڈ\" : u\"د\",\n",
        "        u\"ئ\" : u\"ی\",\n",
        "        u\"ﻨ\" : u\"ن\",\n",
        "        u\"ﺠ\" : u\"ج\",\n",
        "        u\"ﻣ\" : u\"م\",\n",
        "        u\"ﷲ\" : u\"\",\n",
        "        u\"ﻳ\" : u\"ی\",\n",
        "        u\"ٻ\" : u\"ب\",\n",
        "        u\"ٱ\" : u\"ا\",\n",
        "        u\"ڵ\" : u\"ل\",\n",
        "        u\"ﭘ\" : u\"پ\",\n",
        "        u\"ﻪ\" : u\"ه\",\n",
        "        u\"ﻳ\" : u\"ی\",\n",
        "        u\"ٻ\" : u\"ب\",\n",
        "        u\"ں\" : u\"ن\",\n",
        "        u\"ٶ\" : u\"و\",\n",
        "        u\"ٲ\" : u\"ا\",\n",
        "        u\"ہ\" : u\"ه\",\n",
        "        u\"ﻩ\" : u\"ه\",\n",
        "        u\"ﻩ\" : u\"ه\",\n",
        "        u\"ك\" : u\"ک\",\n",
        "        u\"ﺆ\" : u\"و\",\n",
        "        u\"أ\" : u\"ا\",\n",
        "        u\"ﺪ\" : u\"د\"\n",
        "    }\n",
        "    arabic_keys =  re.compile(r\"(\" + \"|\".join(mapping.keys()) + r\")\")\n",
        "    return arabic_keys.sub(lambda x: mapping[x.group()], text)\n",
        "\n",
        "\n",
        "# clean_text function\n",
        "def clean_comment(text, allspace=True, punc=True, sentence=True, only_persian=True):\n",
        "    #remove halph space, new line ('\\n') and '\\r'\n",
        "    text = text.replace('\\u200c', ' ').replace('\\n', '').replace('\\r', '')\n",
        "    # remove punctuations\n",
        "    text = re.sub(symbols_complete_reg, \"\", text)\n",
        "    # remove arabic letters\n",
        "    text = remeove_arabic(text)\n",
        "    # convert spaces to a one space and delete leading and trailing spaces\n",
        "    text = re.sub(\"(\\s)+\", \" \", text)\n",
        "    text = text.strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "IGXA192_6FX0"
      },
      "id": "IGXA192_6FX0",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['clean_comment'] = df_train['comment'].apply(lambda comment:clean_comment(comment))\n",
        "df_eval['clean_comment'] = df_eval['comment'].apply(lambda comment:clean_comment(comment))\n",
        "df_test['clean_comment'] = df_test['comment'].apply(lambda comment:clean_comment(comment))"
      ],
      "metadata": {
        "id": "qFrcOt1w9i8n"
      },
      "id": "qFrcOt1w9i8n",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_id = 500\n",
        "example = df_train['clean_comment'][example_id]\n",
        "example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OtPg_moO-T3Y",
        "outputId": "54fa701b-7494-4738-e10e-761a46636b4c"
      },
      "id": "OtPg_moO-T3Y",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'خیلی عالیه'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1796d3e-6920-44fd-96a0-892bb67ce303",
      "metadata": {
        "id": "d1796d3e-6920-44fd-96a0-892bb67ce303"
      },
      "source": [
        "## FastText Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Skipgram Model"
      ],
      "metadata": {
        "id": "S5mrfStCR2zA"
      },
      "id": "S5mrfStCR2zA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d9e7770-c460-44ec-b8b4-213befad7c44",
      "metadata": {
        "id": "8d9e7770-c460-44ec-b8b4-213befad7c44"
      },
      "outputs": [],
      "source": [
        "# Model 1: Dimension: 100 from # https://github.com/taesiri/PersianWordVectors\n",
        "# SKIPGRAM_MODEL_FILE_ID_1 = '1wPnMG9_GNUVdSgbznQziQc5nMWI3QKNz'\n",
        "# !gdown --id $SKIPGRAM_MODEL_FILE_ID \n",
        "\n",
        "# Model 2: Dimension: 300 from https://fasttext.cc/docs/en/pretrained-vectors.html\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.fa.zip\n",
        "! unzip wiki.fa.zip\n",
        "! rm -rf wiki.fa.zip\n",
        "! rm -rf wiki.fa.vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_LEN = 300 # 100 for Model 1 and 300 for Model 2"
      ],
      "metadata": {
        "id": "MLdM-i-9FWpT"
      },
      "id": "MLdM-i-9FWpT",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load FastText Model"
      ],
      "metadata": {
        "id": "GXOumsIWR9YX"
      },
      "id": "GXOumsIWR9YX"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7d0d02a1-504f-4da8-9254-f31b7386cd32",
      "metadata": {
        "id": "7d0d02a1-504f-4da8-9254-f31b7386cd32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39952dc7-88bd-46a6-b887-159828cce6ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "# Model 1:\n",
        "# model_skipgram = fasttext.load_model('farsi-dedup-skipgram.bin')\n",
        "# Model 2:\n",
        "model_skipgram = fasttext.load_model('wiki.fa.bin')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit Keras Tokenizer on comments\n",
        "comments = df_train['clean_comment'].values\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=3000)\n",
        "tokenizer.fit_on_texts(comments)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size : {}'.format(vocab_size))"
      ],
      "metadata": {
        "id": "_WQEhOzDS8Yw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf9754fa-8762-4d69-b82a-541d0d822b2f"
      },
      "id": "_WQEhOzDS8Yw",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size : 4323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_comments = tokenizer.texts_to_sequences(comments)\n",
        "\n",
        "# example of encoded comments\n",
        "print(\"Comment : {}\".format(comments[1]))\n",
        "print(\"Corresponding Encoding : {}\".format(encoded_comments[1]))"
      ],
      "metadata": {
        "id": "Bs7z2ltRTNCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bed8903-22f6-41d3-8f3d-e34ffa6d5c0d"
      },
      "id": "Bs7z2ltRTNCA",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comment : سلام به دوستای عزیزم عزاداری هاتون قبول باشه\n",
            "Corresponding Encoding : [94, 2, 1716, 817, 1717, 818, 526, 68]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "48de0848-6da0-4c32-b156-d2bdf08a959d",
      "metadata": {
        "id": "48de0848-6da0-4c32-b156-d2bdf08a959d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9881f249-5e76-497d-d797-14eb98793f21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padding Shape: (800, 616)\n"
          ]
        }
      ],
      "source": [
        "# padding\n",
        "SENT_MAX_LEN = max([len(sent) for sent in encoded_comments])\n",
        "padded_sequence = pad_sequences(encoded_comments, maxlen=SENT_MAX_LEN, padding='post')\n",
        "print('Padding Shape: {}'.format(padded_sequence.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "114a59a6-c98a-4659-9eff-ff976fb4b8e6",
      "metadata": {
        "id": "114a59a6-c98a-4659-9eff-ff976fb4b8e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "084b7230-917a-43f1-8aa0-3ee2be39ecd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Matrix Shape is: (4323, 300)\n"
          ]
        }
      ],
      "source": [
        "# initial embedding matrix\n",
        "embedding_matrix = np.zeros((vocab_size, EMBEDDING_LEN))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  embedding_vector = model_skipgram.get_word_vector(word)\n",
        "  # words that cannot be found will be set to 0\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print(f\"Embedding Matrix Shape is: {embedding_matrix.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "81b4d562-56d1-4a94-81d3-7d5899399d50",
      "metadata": {
        "id": "81b4d562-56d1-4a94-81d3-7d5899399d50"
      },
      "outputs": [],
      "source": [
        "# Same procedure with a Unique Tokenizer on Evaluation data\n",
        "eval_comments = df_eval['clean_comment'].values\n",
        "tokenizer.texts_to_matrix(eval_comments)\n",
        "eval_encoded_comments = tokenizer.texts_to_sequences(eval_comments)\n",
        "eval_padded_sequence = pad_sequences(eval_encoded_comments, maxlen=SENT_MAX_LEN, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ae83164d-2b20-4b8b-be62-8317a0c3b29a",
      "metadata": {
        "id": "ae83164d-2b20-4b8b-be62-8317a0c3b29a"
      },
      "outputs": [],
      "source": [
        "# Same procedure with a Unique Tokenizer on Test data\n",
        "test_comments = df_test['clean_comment'].values\n",
        "tokenizer.texts_to_matrix(test_comments)\n",
        "test_encoded_comments = tokenizer.texts_to_sequences(test_comments)\n",
        "test_padded_sequence = pad_sequences(test_encoded_comments, maxlen=SENT_MAX_LEN, padding='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM Model Architecture"
      ],
      "metadata": {
        "id": "adHsUq4GUScc"
      },
      "id": "adHsUq4GUScc"
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM constants\n",
        "LSTM_UNITS = 32"
      ],
      "metadata": {
        "id": "dYh33GkGioq-"
      },
      "id": "dYh33GkGioq-",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = Sequential()\n",
        "model_1.add(Embedding(vocab_size, EMBEDDING_LEN, input_length=SENT_MAX_LEN, weights=[embedding_matrix], trainable=True))\n",
        "model_1.add(Bidirectional(LSTM(EMBEDDING_LEN, return_sequences=True, input_shape=(None, 1))))\n",
        "model_1.add(Dropout(0.2))\n",
        "model_1.add(Bidirectional(LSTM(LSTM_UNITS)))\n",
        "model_1.add(Dropout(0.2))\n",
        "model_1.add(Dense(EMBEDDING_LEN, activation='relu'))\n",
        "model_1.add(Dropout(0.1))\n",
        "model_1.add(Dense(1, activation='sigmoid'))\n",
        "model_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tkv0Pr89RR_S",
        "outputId": "a6ca9b8d-039c-4346-e3b1-9f880d47d6e1"
      },
      "id": "Tkv0Pr89RR_S",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 616, 300)          1296900   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 616, 600)         1442400   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 616, 600)          0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 64)               162048    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 300)               19500     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 300)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 301       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,921,149\n",
            "Trainable params: 2,921,149\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit LSTM Model\n",
        "You can run the cell bellow as much as you want. keep track on validation accuracy and also change the `epochs`. I got my best result in most of the run times at 5th and 10th epochs."
      ],
      "metadata": {
        "id": "RJyJIjngVuUm"
      },
      "id": "RJyJIjngVuUm"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6ede4981-e708-4956-9736-d7b0b6a65f59",
      "metadata": {
        "id": "6ede4981-e708-4956-9736-d7b0b6a65f59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "756308c2-09da-450b-c301-bb703a9bf655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "25/25 [==============================] - 24s 665ms/step - loss: 0.5700 - accuracy: 0.7588 - val_loss: 0.5878 - val_accuracy: 0.7250\n",
            "Epoch 2/5\n",
            "25/25 [==============================] - 14s 575ms/step - loss: 0.5424 - accuracy: 0.7575 - val_loss: 0.5603 - val_accuracy: 0.7250\n",
            "Epoch 3/5\n",
            "25/25 [==============================] - 14s 575ms/step - loss: 0.4898 - accuracy: 0.7725 - val_loss: 0.5922 - val_accuracy: 0.7250\n",
            "Epoch 4/5\n",
            "25/25 [==============================] - 14s 575ms/step - loss: 0.3878 - accuracy: 0.8425 - val_loss: 0.6996 - val_accuracy: 0.7150\n",
            "Epoch 5/5\n",
            "25/25 [==============================] - 14s 577ms/step - loss: 0.2922 - accuracy: 0.8825 - val_loss: 0.6932 - val_accuracy: 0.7200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f81e01f0e10>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "model_1.fit(\n",
        "    padded_sequence, \n",
        "    train_y, \n",
        "    batch_size=32, \n",
        "    epochs=5, \n",
        "    validation_data=(eval_padded_sequence, eval_y)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_1, acc_1 = model_1.evaluate(test_padded_sequence, test_y, verbose=0)\n",
        "print(f'Test Accuracy: {acc_1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAko7El4vMkr",
        "outputId": "961c9380-6d14-4d60-b0a7-941c2233a4b8"
      },
      "id": "tAko7El4vMkr",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7352941036224365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_1 = model_1.predict(test_padded_sequence)\n",
        "y_pred_1 = np.array((pred_1 > 0.5).astype(int)[:,0])\n",
        "print(confusion_matrix(y_true=test_y, y_pred=y_pred_1))\n",
        "print(classification_report(y_true=test_y, y_pred=y_pred_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqto7tgjCi4j",
        "outputId": "d5a795a7-e699-4440-be62-983d619cc5ef"
      },
      "id": "pqto7tgjCi4j",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 21  31]\n",
            " [ 14 104]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.40      0.48        52\n",
            "           1       0.77      0.88      0.82       118\n",
            "\n",
            "    accuracy                           0.74       170\n",
            "   macro avg       0.69      0.64      0.65       170\n",
            "weighted avg       0.72      0.74      0.72       170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Model Architecture"
      ],
      "metadata": {
        "id": "C_ni4QYf_xNk"
      },
      "id": "C_ni4QYf_xNk"
    },
    {
      "cell_type": "code",
      "source": [
        "## CNN Constants\n",
        "KERNEL_SIZE = 3\n",
        "FILTERS = 256"
      ],
      "metadata": {
        "id": "MVk-i5iE9ayI"
      },
      "id": "MVk-i5iE9ayI",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = Sequential()\n",
        "model_2.add(Embedding(vocab_size, embedding_matrix.shape[1], weights=[embedding_matrix], trainable=False))\n",
        "model_2.add(Conv1D(filters=FILTERS, kernel_size=KERNEL_SIZE, activation='relu'))\n",
        "model_2.add(GlobalMaxPooling1D())\n",
        "model_2.add(Dense(FILTERS, activation='relu'))\n",
        "model_2.add(Dense(1, activation='sigmoid'))\n",
        "model_2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfs4V5H37reB",
        "outputId": "19478e4e-2f70-4aa2-d649-d1757341593f"
      },
      "id": "lfs4V5H37reB",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 300)         1296900   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, None, 256)         230656    \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 256)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,593,605\n",
            "Trainable params: 296,705\n",
            "Non-trainable params: 1,296,900\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit CNN Model\n",
        "You can run the cell bellow as much as you want. keep track on validation accuracy and also change the `epochs`. I got my best result in most of the run times at 5th epoch."
      ],
      "metadata": {
        "id": "akaz6n0t_bTS"
      },
      "id": "akaz6n0t_bTS"
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.fit(\n",
        "    padded_sequence, \n",
        "    train_y, \n",
        "    batch_size=32, \n",
        "    epochs=5, \n",
        "    validation_data=(eval_padded_sequence, eval_y)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbVoK7r29R1S",
        "outputId": "856920a1-7fbe-4359-b9dd-3fcb7c89715f"
      },
      "id": "dbVoK7r29R1S",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "25/25 [==============================] - 3s 31ms/step - loss: 0.5558 - accuracy: 0.7500 - val_loss: 0.5590 - val_accuracy: 0.7450\n",
            "Epoch 2/5\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.4407 - accuracy: 0.7975 - val_loss: 0.5386 - val_accuracy: 0.7600\n",
            "Epoch 3/5\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.2600 - accuracy: 0.9100 - val_loss: 0.6423 - val_accuracy: 0.7600\n",
            "Epoch 4/5\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0946 - accuracy: 0.9887 - val_loss: 0.6781 - val_accuracy: 0.7400\n",
            "Epoch 5/5\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0281 - accuracy: 0.9962 - val_loss: 0.8345 - val_accuracy: 0.7350\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f81776c0850>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_2, acc_2 = model_2.evaluate(test_padded_sequence, test_y, verbose=0)\n",
        "print('Test Accuracy: %f' % (acc_2*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0E9HNy_-NbD",
        "outputId": "40a83f61-7609-4978-b359-4a66068a6b7f"
      },
      "id": "S0E9HNy_-NbD",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 77.647060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_2 = model_2.predict(test_padded_sequence)\n",
        "y_pred_2 = np.array((pred_2 > 0.5).astype(int)[:,0])\n",
        "print(confusion_matrix(y_true=test_y, y_pred=y_pred_2))\n",
        "print(classification_report(y_true=test_y, y_pred=y_pred_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9sTL8h4Ae6q",
        "outputId": "bb7814d3-5bc3-4998-bee0-0aff1e34474f"
      },
      "id": "z9sTL8h4Ae6q",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 18  34]\n",
            " [  4 114]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.35      0.49        52\n",
            "           1       0.77      0.97      0.86       118\n",
            "\n",
            "    accuracy                           0.78       170\n",
            "   macro avg       0.79      0.66      0.67       170\n",
            "weighted avg       0.78      0.78      0.74       170\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}