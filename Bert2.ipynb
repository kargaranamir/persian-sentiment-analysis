{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Before You Run\n",
        "make a `data` drectory and upload data (eval, test and train csvs)"
      ],
      "metadata": {
        "id": "IDh-HjxqmTcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir data"
      ],
      "metadata": {
        "id": "PuPsSNI5lZ1Z"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install hazm\n",
        "! pip install ktrain # ktrain is a lightweight wrapper for the deep learning library TensorFlow Keras"
      ],
      "metadata": {
        "id": "DTKXZusSQNl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "I0YkX5CXepfi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "07ab578b-d556-407c-a357-77c15b17be3b"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import GlobalMaxPool1D, MaxPooling1D, GlobalMaxPooling1D, Conv1D\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from hazm import word_tokenize, Normalizer\n",
        "\n",
        "import ktrain\n",
        "from ktrain import text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "NIvkU8e2eSm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = 'data/'\n",
        "PATH = PATH.rstrip('/')\n",
        "\n",
        "# Classes\n",
        "class_names = ['Positive', 'Negative']\n",
        "\n",
        "# Train\n",
        "df_train = pd.read_csv(PATH + '/train.csv')\n",
        "df_train.columns = ['index', 'comment', 'rate']\n",
        "\n",
        "# Evaluation\n",
        "df_eval = pd.read_csv(PATH + '/eval.csv')\n",
        "df_eval.columns = ['index', 'comment', 'rate']\n",
        "\n",
        "# Test\n",
        "df_test = pd.read_csv(PATH + '/test.csv')\n",
        "df_test.columns = ['index', 'comment', 'rate']"
      ],
      "metadata": {
        "id": "yBYACIpBxCaa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess"
      ],
      "metadata": {
        "id": "g3UJaMTV6B9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = Normalizer() # Hazm normlizer\n",
        "symbols_complete_reg = re.compile(r\"(\\d|\\\"|'ٍ|¬|[؛“،,”‘۔’’‘–]|[|\\.÷+\\]\\[\\)\\(\\:\\-\\?»\\=\\{}\\*«»_…\\؟!/ـ]|[۰'ٓ۫'ٔ]|[ٓٔ]|[ًٌٍْﹼ،َُِّ«ٰ»ٖء])\")\n",
        "\n",
        "def remeove_arabic(text):\n",
        "    # remove arabic alphabet\n",
        "    mapping = {\n",
        "        u\"ۀ\" : u\"ه\",\n",
        "        u\"ة\" : u\"ت\",\n",
        "        u\"ي\" : u\"ی\",\n",
        "        u\"ؤ\" : u\"و\",\n",
        "        u\"إ\" : u\"ا\",\n",
        "        u\"ٹ\" : u\"ت\",\n",
        "        u\"ڈ\" : u\"د\",\n",
        "        u\"ئ\" : u\"ی\",\n",
        "        u\"ﻨ\" : u\"ن\",\n",
        "        u\"ﺠ\" : u\"ج\",\n",
        "        u\"ﻣ\" : u\"م\",\n",
        "        u\"ﷲ\" : u\"\",\n",
        "        u\"ﻳ\" : u\"ی\",\n",
        "        u\"ٻ\" : u\"ب\",\n",
        "        u\"ٱ\" : u\"ا\",\n",
        "        u\"ڵ\" : u\"ل\",\n",
        "        u\"ﭘ\" : u\"پ\",\n",
        "        u\"ﻪ\" : u\"ه\",\n",
        "        u\"ﻳ\" : u\"ی\",\n",
        "        u\"ٻ\" : u\"ب\",\n",
        "        u\"ں\" : u\"ن\",\n",
        "        u\"ٶ\" : u\"و\",\n",
        "        u\"ٲ\" : u\"ا\",\n",
        "        u\"ہ\" : u\"ه\",\n",
        "        u\"ﻩ\" : u\"ه\",\n",
        "        u\"ﻩ\" : u\"ه\",\n",
        "        u\"ك\" : u\"ک\",\n",
        "        u\"ﺆ\" : u\"و\",\n",
        "        u\"أ\" : u\"ا\",\n",
        "        u\"ﺪ\" : u\"د\"\n",
        "    }\n",
        "    arabic_keys =  re.compile(r\"(\" + \"|\".join(mapping.keys()) + r\")\")\n",
        "    return arabic_keys.sub(lambda x: mapping[x.group()], text)\n",
        "\n",
        "\n",
        "# clean_text function\n",
        "def clean_comment(text, allspace=True, punc=True, sentence=True, only_persian=True):\n",
        "    #remove halph space, new line ('\\n') and '\\r'\n",
        "    text = text.replace('\\u200c', ' ').replace('\\n', '').replace('\\r', '')\n",
        "    # remove punctuations\n",
        "    text = re.sub(symbols_complete_reg, \"\", text)\n",
        "    # remove arabic letters\n",
        "    text = remeove_arabic(text)\n",
        "    # convert spaces to a one space and delete leading and trailing spaces\n",
        "    text = re.sub(\"(\\s)+\", \" \", text)\n",
        "    text = text.strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "IGXA192_6FX0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['clean_comment'] = df_train['comment'].apply(lambda comment:clean_comment(comment))\n",
        "df_eval['clean_comment'] = df_eval['comment'].apply(lambda comment:clean_comment(comment))\n",
        "df_test['clean_comment'] = df_test['comment'].apply(lambda comment:clean_comment(comment))"
      ],
      "metadata": {
        "id": "qFrcOt1w9i8n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Lables\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# X\n",
        "x_train = df_train['clean_comment'].values\n",
        "x_eval = df_eval['clean_comment'].values\n",
        "x_test = df_test['clean_comment'].values\n",
        "\n",
        "# Y\n",
        "y_train = label_encoder.fit_transform((df_train['rate'] >= 0).astype(int))\n",
        "y_eval = label_encoder.fit_transform((df_eval['rate'] >= 0).astype(int))\n",
        "y_test = label_encoder.fit_transform((df_test['rate'] >= 0).astype(int))"
      ],
      "metadata": {
        "id": "OtPg_moO-T3Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build, train, and validate model (Transformer is wrapper around transformers library)\n",
        "\n",
        "MODEL_NAME = 'HooshvareLab/distilbert-fa-zwnj-base'  # replace this with model of choice\n",
        "transformer_model = text.Transformer(MODEL_NAME, maxlen=500, class_names=class_names)\n",
        "trn = transformer_model.preprocess_train(x_train, y_train)\n",
        "val = transformer_model.preprocess_test(x_eval, y_eval)\n",
        "classifier_model = transformer_model.get_classifier()\n",
        "learner = ktrain.get_learner(classifier_model, train_data=trn, val_data=val, batch_size=6)\n",
        "learner.fit_onecycle(5e-5, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "OqMA28aSM8_F",
        "outputId": "0f078385-8306-4268-8d07-9818f7b15c8e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessing train...\n",
            "language: fa\n",
            "train sequence lengths:\n",
            "\tmean : 23\n",
            "\t95percentile : 59\n",
            "\t99percentile : 126\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: fa\n",
            "test sequence lengths:\n",
            "\tmean : 24\n",
            "\t95percentile : 49\n",
            "\t99percentile : 184\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 5e-05...\n",
            "Epoch 1/4\n",
            "134/134 [==============================] - 112s 760ms/step - loss: 0.5465 - accuracy: 0.7525 - val_loss: 0.5400 - val_accuracy: 0.7400\n",
            "Epoch 2/4\n",
            "134/134 [==============================] - 100s 743ms/step - loss: 0.4711 - accuracy: 0.7850 - val_loss: 0.5186 - val_accuracy: 0.6850\n",
            "Epoch 3/4\n",
            "134/134 [==============================] - 100s 744ms/step - loss: 0.3034 - accuracy: 0.8650 - val_loss: 0.6497 - val_accuracy: 0.7950\n",
            "Epoch 4/4\n",
            "134/134 [==============================] - 100s 744ms/step - loss: 0.0769 - accuracy: 0.9712 - val_loss: 0.9278 - val_accuracy: 0.7300\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff496de4c90>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tst = transformer_model.preprocess_test(x_test, y_test)\n",
        "learner.validate(val_data=tst, class_names=transformer_model.get_classes()) # class_names must be string values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "bdsOYYJCQxh2",
        "outputId": "be9b9b33-33ca-4eec-d89e-708edcb1277a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessing test...\n",
            "language: fa\n",
            "test sequence lengths:\n",
            "\tmean : 24\n",
            "\t95percentile : 55\n",
            "\t99percentile : 121\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.74      0.48      0.58        52\n",
            "    Negative       0.80      0.92      0.86       118\n",
            "\n",
            "    accuracy                           0.79       170\n",
            "   macro avg       0.77      0.70      0.72       170\n",
            "weighted avg       0.78      0.79      0.77       170\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 25,  27],\n",
              "       [  9, 109]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}