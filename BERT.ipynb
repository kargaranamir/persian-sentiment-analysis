{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2BoNlspOns0"
      },
      "source": [
        "## Bert Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnIZugvTOns1",
        "outputId": "a65428fb-3785-4b15-904c-247047209957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hazm in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: libwapiti>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from hazm) (0.2.1)\n",
            "Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.7/dist-packages (from hazm) (3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers\n",
        "\n",
        "! pip install hazm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Required Libraries"
      ],
      "metadata": {
        "id": "-RqHVWaX17xd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8Owko4ikCQL"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig, BertTokenizer\n",
        "from transformers import BertModel\n",
        "\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import os\n",
        "\n",
        "from hazm import word_tokenize, Normalizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import collections"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read Data"
      ],
      "metadata": {
        "id": "EtG5c6cy4pX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = 'data/'\n",
        "PATH = PATH.rstrip('/')\n",
        "\n",
        "# Train\n",
        "df_train = pd.read_csv(PATH + '/train.csv')\n",
        "df_train.columns = ['index', 'comment', 'rate']\n",
        "\n",
        "# Evaluation\n",
        "df_eval = pd.read_csv(PATH + '/eval.csv')\n",
        "df_eval.columns = ['index', 'comment', 'rate']\n",
        "\n",
        "# Test\n",
        "df_test = pd.read_csv(PATH + '/test.csv')\n",
        "df_test.columns = ['index', 'comment', 'rate']\n",
        "\n",
        "# Create Lables\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "train_y = label_encoder.fit_transform((df_train['rate'] >= 0).astype(int))\n",
        "eval_y = label_encoder.fit_transform((df_eval['rate'] >= 0).astype(int))\n",
        "test_y = label_encoder.fit_transform((df_test['rate'] >= 0).astype(int))"
      ],
      "metadata": {
        "id": "dK6tzMYR4oQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model General Config"
      ],
      "metadata": {
        "id": "m_ZHavWq2S0v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foFUEVSPP6tW"
      },
      "outputs": [],
      "source": [
        "# Model Config\n",
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "VALID_BATCH_SIZE = 32\n",
        "TEST_BATCH_SIZE = 16\n",
        "\n",
        "EPOCHS = 12\n",
        "# Every EEVERY_EPOCH print status\n",
        "EEVERY_EPOCH = 1000\n",
        "LEARNING_RATE = 2e-5\n",
        "CLIP = 0.0\n",
        "\n",
        "MODEL_NAME_OR_PATH = 'HooshvareLab/bert-fa-base-uncased'\n",
        "OUTPUT_PATH = '/content/bert-fa-base/pytorch_model.bin'\n",
        "\n",
        "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT Tokenizer"
      ],
      "metadata": {
        "id": "w_DyS7kK2afM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBDHHD5GQHdD"
      },
      "outputs": [],
      "source": [
        "# setup the tokenizer and configuration\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME_OR_PATH, return_dict=False)\n",
        "config = BertConfig.from_pretrained(MODEL_NAME_OR_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample"
      ],
      "metadata": {
        "id": "jGSJciIR21Mw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fY92wByDRNz-",
        "tags": []
      },
      "outputs": [],
      "source": [
        "sample = 'از این محصول بدم اومده!'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwZH9JzBQdGB"
      },
      "outputs": [],
      "source": [
        "tokens = tokenizer.tokenize(sample)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(f'Tokens: {tokenizer.convert_tokens_to_string(tokens)}')\n",
        "print(f'Token IDs: {token_ids}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Md9LZv7bQs8n"
      },
      "outputs": [],
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "    sample,\n",
        "    max_length=32,\n",
        "    truncation=True,\n",
        "    add_special_tokens=True,\n",
        "    return_token_type_ids=True,\n",
        "    return_attention_mask=True,\n",
        "    padding='max_length',\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "print(f'Keys: {encoding.keys()}\\n')\n",
        "for k in encoding.keys():\n",
        "    print(f'{k}:\\n{encoding[k]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Torch Dataset"
      ],
      "metadata": {
        "id": "rgSEFNcA266S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hcmvb9S8RRF-"
      },
      "outputs": [],
      "source": [
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "    \"\"\" Create a PyTorch dataset for Digikala SentimentDataset. \"\"\"\n",
        "\n",
        "    def __init__(self, tokenizer, comments, targets, is_predict=False, max_len=128):\n",
        "        self.comments = comments\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.is_predict = is_predict\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        comment = str(self.comments[item])\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            comment,\n",
        "            add_special_tokens=True,\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt')\n",
        "        \n",
        "        inputs = {}\n",
        "        \n",
        "        inputs = {\n",
        "            'comment': comment,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'token_type_ids': encoding['token_type_ids'].flatten(),\n",
        "        }\n",
        "\n",
        "        if not self.is_predict:\n",
        "            inputs['targets'] = torch.tensor(self.targets[item], dtype=torch.long)\n",
        "\n",
        "        return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WI24KRj6SGMb"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(x, y, tokenizer, max_len, batch_size, is_predict=False):\n",
        "    dataset = SentimentDataset(\n",
        "        comments=x,\n",
        "        targets=y,\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len,\n",
        "        is_predict=is_predict)\n",
        "    \n",
        "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_FBYJbWSKfA"
      },
      "outputs": [],
      "source": [
        "train_data_loader = create_data_loader(df_train['comment'].to_numpy(), train_y, tokenizer, MAX_LEN, TRAIN_BATCH_SIZE)\n",
        "valid_data_loader = create_data_loader(df_eval['comment'].to_numpy(), eval_y, tokenizer, MAX_LEN, VALID_BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Batch"
      ],
      "metadata": {
        "id": "hGnc2gNKAO6k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeleE_qzSgnT"
      },
      "outputs": [],
      "source": [
        "# We will make prediction over sample batch for example\n",
        "sample_batch = next(iter(train_data_loader))\n",
        "sample_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentiment Model"
      ],
      "metadata": {
        "id": "ASwzdscG_vLG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGssla7sSnLg"
      },
      "outputs": [],
      "source": [
        "class SentimentModel(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(SentimentModel, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(MODEL_NAME_OR_PATH, return_dict=False)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        _, pooled_output = self.bert(\n",
        "            input_ids=input_ids, \n",
        "            attention_mask=attention_mask, \n",
        "            token_type_ids=token_type_ids)\n",
        "        \n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EMzfkzkS2L1"
      },
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "pt_model = None\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "aojqy0t_UScK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBZEoL0MS43a"
      },
      "outputs": [],
      "source": [
        "pt_model = SentimentModel(config=config)\n",
        "pt_model = pt_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make Prediction Based on Sample Batch\n",
        "Here is only BERT Model result over sample batch without any fine-tuning"
      ],
      "metadata": {
        "id": "ySsQIb3zA9bs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrMD0hiKiRpm"
      },
      "outputs": [],
      "source": [
        "result = pt_model(sample_batch['input_ids'].to(device), \n",
        "                   sample_batch['attention_mask'].to(device),\n",
        "                   sample_batch['token_type_ids'].to(device))\n",
        "\n",
        "# Make Prediction\n",
        "_, predictions = torch.max(result, dim=1)\n",
        "\n",
        "for i, comment in enumerate(sample_batch['comment']):\n",
        "    print(str(comment) + \" : \" + str(predictions[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6m3I4wuTqie"
      },
      "outputs": [],
      "source": [
        "def stack_y(y_true, y_pred):\n",
        "    y_true = torch.stack(y_true).cpu().detach().numpy()\n",
        "    y_pred = torch.stack(y_pred).cpu().detach().numpy()\n",
        "    return [y_true, y_pred]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Method"
      ],
      "metadata": {
        "id": "Fw-I3DmoOvjE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E78X9PjqUi-3"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmCBcwACS_En"
      },
      "outputs": [],
      "source": [
        "def train(model, \n",
        "          data_loader, \n",
        "          step=0, \n",
        "          print_every_step=100, \n",
        "          eval_min_loss=np.Inf,\n",
        "          eval_data_loader=None, \n",
        "          clip=0.0):\n",
        "    \n",
        "\n",
        "    # Tell Model that We are training model\n",
        "    model.train()\n",
        "\n",
        "    # Store Losses in each step\n",
        "    losses = []\n",
        "    # Each Step Prediction\n",
        "    y_pred = []\n",
        "    # Each Step True Label\n",
        "    y_true = []\n",
        "\n",
        "    # AdamW Optimizer\n",
        "    optimizer = AdamW(pt_model.parameters(), lr=LEARNING_RATE, correct_bias=False)\n",
        "\n",
        "    # Loss Function\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Total Required Steps\n",
        "    total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "    # Scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0,\n",
        "                                                num_training_steps=total_steps)\n",
        "    \n",
        "    for batch in tqdm(data_loader, total=len(data_loader), desc=\"Training Process \"):\n",
        "        step += 1\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        token_type_ids = batch['token_type_ids']\n",
        "        targets = batch['targets']\n",
        "\n",
        "        # Using CUDA if available\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        token_type_ids = token_type_ids.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Clear previous gradiant optimized variables\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Predict results\n",
        "        results = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids)\n",
        "        \n",
        "        # convert output probabilities to predicted class\n",
        "        _, predictions = torch.max(results, dim=1)\n",
        "\n",
        "        # calculate the batch loss and append it to end of Losses list\n",
        "        loss = loss_fn(results, targets)\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        # Also Append predictions and true labels\n",
        "        y_pred.extend(predictions)\n",
        "        y_true.extend(targets)\n",
        "\n",
        "        # Compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        if clip > 0.0:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "\n",
        "        # perform optimization step\n",
        "        optimizer.step()\n",
        "\n",
        "        # perform scheduler step\n",
        "        scheduler.step()\n",
        "\n",
        "        # Stack True labels and Predictions\n",
        "        train_y = stack_y(y_true, y_pred)\n",
        "\n",
        "        # Calculate Average Loss\n",
        "        train_loss = np.mean(losses)\n",
        "        \n",
        "        if step % print_every_step == 0:\n",
        "            eval_y, eval_loss = evaluation(model, eval_data_loader, loss_fn)\n",
        "            eval_score = acc_and_f1(eval_y[0], eval_y[1], average='weighted')\n",
        "\n",
        "            print('Epoch: {}/{}...'.format(epoch, epochs))\n",
        "            print('Step: {}...'.format(step))\n",
        "            \n",
        "            print('Train Loss: {:.6f}...'.format(train_loss))\n",
        "            print('Train Acc: {:.3f}...'.format(accuracy_score(train_y[0], train_y[1])))\n",
        "\n",
        "            print('Valid Loss: {:.6f}...'.format(eval_loss))\n",
        "            print('Valid Acc: {:.3f}...'.format(accuracy_score(eval_y[0], eval_y[1])))\n",
        "\n",
        "\n",
        "            if eval_loss <= eval_min_loss:\n",
        "                print('Validation Loss Change is : ({:.5f} --> {:.5f}).'.format(eval_loss_min, eval_loss))\n",
        "                eval_min_loss = eval_loss\n",
        "\n",
        "                print(\"Model Saved.\")\n",
        "                torch.save(model.state_dict(), output_path)\n",
        "\n",
        "    # Stack True labels and Predictions\n",
        "    train_y = stack_y(y_true, y_pred)\n",
        "\n",
        "    # Calculate Average Loss\n",
        "    train_loss = np.mean(losses)\n",
        "\n",
        "    return train_y, train_loss, step, eval_min_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Method"
      ],
      "metadata": {
        "id": "-GgFTfcDO0_z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hS5ztsgTw15"
      },
      "outputs": [],
      "source": [
        "def evaluation(model, data_loader, loss_fn):\n",
        "\n",
        "    # Tell Model that We are evaluating model\n",
        "    model.eval()\n",
        "\n",
        "    # Store Losses in each step\n",
        "    losses = []\n",
        "    # Each Step Prediction\n",
        "    y_pred = []\n",
        "    # Each Step True Label\n",
        "    y_true = []\n",
        "\n",
        "\n",
        "    # Stop Optimizing on evaluation data\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(data_loader, total=len(data_loader), desc=\"Evaluation Process\"):\n",
        "            \n",
        "            input_ids = batch['input_ids']\n",
        "            attention_mask = batch['attention_mask']\n",
        "            token_type_ids = batch['token_type_ids']\n",
        "            targets = batch['targets']\n",
        "\n",
        "            # Using CUDA if available\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # Predict results\n",
        "            results = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids)\n",
        "            \n",
        "            # convert output probabilities to predicted class\n",
        "            _, predictions = torch.max(results, dim=1)\n",
        "\n",
        "            # calculate the batch loss and append it to end of Losses list\n",
        "            loss = loss_fn(results, targets)\n",
        "            losses.append(loss.item())\n",
        "            \n",
        "            # Also Append predictions and true labels\n",
        "            y_pred.extend(predictions)\n",
        "            y_true.extend(targets)\n",
        "    \n",
        "    # Stack True labels and Predictions\n",
        "    eval_y = stack_y(y_true, y_pred)\n",
        "\n",
        "    # Calculate Average Loss\n",
        "    eval_loss = np.mean(losses)\n",
        "\n",
        "    return eval_y, eval_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Model"
      ],
      "metadata": {
        "id": "LqP6WGbMFyG7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2-6ylDNTz5g"
      },
      "outputs": [],
      "source": [
        "step = 0\n",
        "eval_min_loss = np.Inf\n",
        "history = collections.defaultdict(list)\n",
        "\n",
        "for epoch in tqdm(range(1, EPOCHS + 1), desc=\"epochs...\"):\n",
        "    train_y, train_loss, step, eval_min_loss = train(\n",
        "        model=pt_model, \n",
        "        data_loader=train_data_loader, \n",
        "        step=step, \n",
        "        print_every_step=EEVERY_EPOCH, \n",
        "        eval_min_loss=eval_min_loss,\n",
        "        eval_data_loader=valid_data_loader,\n",
        "        clip=CLIP)\n",
        "    \n",
        "    history['train_accuracy'].append(accuracy_score(train_y[0], train_y[1]))\n",
        "    history['train_f1'].append(f1_score(train_y[0], train_y[1], average='weighted'))\n",
        "    history['train_loss'].append(train_loss)\n",
        "\n",
        "    eval_y, eval_loss = evaluation(\n",
        "        model=pt_model, \n",
        "        data_loader=valid_data_loader, \n",
        "        loss_fn=nn.CrossEntropyLoss())\n",
        "    \n",
        "    history['eval_accuracy'].append(accuracy_score(eval_y[0], eval_y[1]))\n",
        "    history['eval_f1'].append(f1_score(eval_y[0], eval_y[1], average='weighted'))\n",
        "    history['eval_loss'].append(eval_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict Method"
      ],
      "metadata": {
        "id": "V-X2P_pPWM4I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcHEi4yYUXxL"
      },
      "outputs": [],
      "source": [
        "def predict(model, comments, tokenizer, max_len=256, batch_size=32):\n",
        "    data_loader = create_data_loader(comments, None, tokenizer, max_len, batch_size, is_predict=True)\n",
        "    \n",
        "    # Append predictions into this list\n",
        "    predictions_list = []\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(data_loader, position=0):\n",
        "            input_ids = batch['input_ids']\n",
        "            attention_mask = batch['attention_mask']\n",
        "            token_type_ids = batch['token_type_ids']\n",
        "\n",
        "            # Using CUDA if available\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            \n",
        "            # Predict results\n",
        "            results = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids)\n",
        "            \n",
        "            # convert output probabilities to predicted class\n",
        "            _, predictions = torch.max(results, dim=1)\n",
        "\n",
        "            predictions_list.extend(predictions)\n",
        "\n",
        "    predictions = torch.stack(predictions_list).cpu().detach().numpy()\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict Test Data"
      ],
      "metadata": {
        "id": "0eBIHve0WRbD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVSiBX8DH4K-"
      },
      "outputs": [],
      "source": [
        "test_comments = df_test['comment'].to_numpy()\n",
        "predictions = predict(pt_model, test_comments, tokenizer, max_len=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy"
      ],
      "metadata": {
        "id": "7Vt4ewpsXUhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy: {}'.format(accuracy_score(test_y, predictions)))"
      ],
      "metadata": {
        "id": "OY4jy9V4XEaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F1-Score"
      ],
      "metadata": {
        "id": "5OF6CMdWW-sI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHpsAqpxIJa5"
      },
      "outputs": [],
      "source": [
        "print('F1: {}'.format(f1_score(test_y, predictions, average=\"weighted\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification Report"
      ],
      "metadata": {
        "id": "E8dRHZU2W7Tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(test_y, predictions, target_names=['positive','negative']))"
      ],
      "metadata": {
        "id": "E8lF7TwuW6Yr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}