{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2BoNlspOns0"
      },
      "source": [
        "## Bert Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnIZugvTOns1",
        "outputId": "e87c70e6-3756-44ab-ada1-412425d48dd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hazm in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: libwapiti>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from hazm) (0.2.1)\n",
            "Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.7/dist-packages (from hazm) (3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers\n",
        "\n",
        "! pip install hazm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Required Libraries"
      ],
      "metadata": {
        "id": "-RqHVWaX17xd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e8Owko4ikCQL"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig, BertTokenizer\n",
        "from transformers import BertModel\n",
        "\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import os\n",
        "\n",
        "from hazm import word_tokenize, Normalizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read Data"
      ],
      "metadata": {
        "id": "EtG5c6cy4pX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = 'data/'\n",
        "PATH = PATH.rstrip('/')\n",
        "\n",
        "# Train\n",
        "df_train = pd.read_csv(PATH + '/train.csv')\n",
        "df_train.columns = ['index', 'comment', 'rate']\n",
        "\n",
        "# Evaluation\n",
        "df_eval = pd.read_csv(PATH + '/eval.csv')\n",
        "df_eval.columns = ['index', 'comment', 'rate']\n",
        "\n",
        "# Test\n",
        "df_test = pd.read_csv(PATH + '/test.csv')\n",
        "df_test.columns = ['index', 'comment', 'rate']\n",
        "\n",
        "# Create Lables\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "train_y = label_encoder.fit_transform((df_train['rate'] >= 0).astype(int))\n",
        "eval_y = label_encoder.fit_transform((df_eval['rate'] >= 0).astype(int))\n",
        "test_y = label_encoder.fit_transform((df_test['rate'] >= 0).astype(int))"
      ],
      "metadata": {
        "id": "dK6tzMYR4oQr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model General Config"
      ],
      "metadata": {
        "id": "m_ZHavWq2S0v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "foFUEVSPP6tW"
      },
      "outputs": [],
      "source": [
        "# Model Config\n",
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 16\n",
        "TEST_BATCH_SIZE = 16\n",
        "\n",
        "EPOCHS = 3\n",
        "# Every EEVERY_EPOCH print status\n",
        "EEVERY_EPOCH = 1000\n",
        "LEARNING_RATE = 2e-5\n",
        "CLIP = 0.0\n",
        "\n",
        "MODEL_NAME_OR_PATH = 'HooshvareLab/bert-fa-base-uncased'\n",
        "OUTPUT_PATH = '/content/bert-fa-base/pytorch_model.bin'\n",
        "\n",
        "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT Tokenizer"
      ],
      "metadata": {
        "id": "w_DyS7kK2afM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wBDHHD5GQHdD"
      },
      "outputs": [],
      "source": [
        "# setup the tokenizer and configuration\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME_OR_PATH, return_dict=False)\n",
        "config = BertConfig.from_pretrained(MODEL_NAME_OR_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample"
      ],
      "metadata": {
        "id": "jGSJciIR21Mw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fY92wByDRNz-",
        "tags": []
      },
      "outputs": [],
      "source": [
        "sample = 'از این محصول بدم اومده!'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwZH9JzBQdGB",
        "outputId": "bc776116-14e6-4629-c42f-58d42847859f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: از این محصول بدم اومده !\n",
            "Token IDs: [2791, 2802, 3573, 19910, 36711, 1001]\n"
          ]
        }
      ],
      "source": [
        "tokens = tokenizer.tokenize(sample)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(f'Tokens: {tokenizer.convert_tokens_to_string(tokens)}')\n",
        "print(f'Token IDs: {token_ids}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md9LZv7bQs8n",
        "outputId": "94a02c2d-ba76-4288-c75c-19fc118ff02f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
            "\n",
            "input_ids:\n",
            "tensor([[    2,  2791,  2802,  3573, 19910, 36711,  1001,     4,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0]])\n",
            "token_type_ids:\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "attention_mask:\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ],
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "    sample,\n",
        "    max_length=32,\n",
        "    truncation=True,\n",
        "    add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "    return_token_type_ids=True,\n",
        "    return_attention_mask=True,\n",
        "    padding='max_length',\n",
        "    return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "print(f'Keys: {encoding.keys()}\\n')\n",
        "for k in encoding.keys():\n",
        "    print(f'{k}:\\n{encoding[k]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Torch Dataset"
      ],
      "metadata": {
        "id": "rgSEFNcA266S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Hcmvb9S8RRF-"
      },
      "outputs": [],
      "source": [
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "    \"\"\" Create a PyTorch dataset for Digikala SentimentDataset. \"\"\"\n",
        "\n",
        "    def __init__(self, tokenizer, comments, targets, max_len=128):\n",
        "        self.comments = comments\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        comment = str(self.comments[item])\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            comment,\n",
        "            add_special_tokens=True,\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt')\n",
        "        \n",
        "        inputs = {}\n",
        "        \n",
        "        if not self.targets:\n",
        "          inputs['targets'] = torch.tensor(self.targets[item], dtype=torch.long)\n",
        "\n",
        "        inputs = {\n",
        "            'comment': comment,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'token_type_ids': encoding['token_type_ids'].flatten(),\n",
        "        }\n",
        "\n",
        "        return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WI24KRj6SGMb"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(x, y, tokenizer, max_len, batch_size):\n",
        "    dataset = SentimentDataset(\n",
        "        comments=x,\n",
        "        targets=y,\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len)\n",
        "    \n",
        "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0_FBYJbWSKfA"
      },
      "outputs": [],
      "source": [
        "train_data_loader = create_data_loader(df_train['comment'].to_numpy(), train_y, tokenizer, MAX_LEN, TRAIN_BATCH_SIZE)\n",
        "valid_data_loader = create_data_loader(df_eval['comment'].to_numpy(), eval_y, tokenizer, MAX_LEN, VALID_BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Batch"
      ],
      "metadata": {
        "id": "hGnc2gNKAO6k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CeleE_qzSgnT"
      },
      "outputs": [],
      "source": [
        "# We will make prediction over sample batch for example\n",
        "sample_batch = next(iter(train_data_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentiment Model"
      ],
      "metadata": {
        "id": "ASwzdscG_vLG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cGssla7sSnLg"
      },
      "outputs": [],
      "source": [
        "class SentimentModel(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(SentimentModel, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(MODEL_NAME_OR_PATH, return_dict=False)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        _, pooled_output = self.bert(\n",
        "            input_ids=input_ids, \n",
        "            attention_mask=attention_mask, \n",
        "            token_type_ids=token_type_ids)\n",
        "        \n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EMzfkzkS2L1",
        "outputId": "8c3171b9-8539-449c-cbfd-f07bfa7b02db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch, gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "pt_model = None\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "aojqy0t_UScK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBZEoL0MS43a",
        "outputId": "6c7a21c9-8c91-49ff-a30a-735930ae307d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "pt_model = SentimentModel(config=config)\n",
        "pt_model = pt_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make Prediction Based on Sample Batch\n",
        "Here is only BERT Model result over sample batch without any fine-tuning"
      ],
      "metadata": {
        "id": "ySsQIb3zA9bs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrMD0hiKiRpm",
        "outputId": "9bbcc0c3-eff4-4f66-e59d-86ee1ab31f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "پردازنده های Core i5 و Core i3 نیز ذاتا دو هسته ای با توان ساختن دو هسته‌ی مجازی دیگر هستند. : tensor(0)\n",
            "سلام به دوستای عزیزم \r\n",
            "عزاداری هاتون قبول باشه : tensor(0)\n",
            "کلا پولتون رو دور نریزیزد : tensor(0)\n",
            "از صمیم قلب امیدوارم دایانا با کارن بمونه و پوریا رو فراموش کنه : tensor(0)\n",
            "آنطور که اپل ادعا می کند آیپاد شافل دارای طراحی فوق العاده است، که البته ادعایی غیر واقعی نیست. : tensor(0)\n",
            "در کل کفش بدی نیست ولی من خودم دادشتم دور دوخت ولی با این قیمت این کفش ارزش خرید نداره : tensor(0)\n",
            "به دلیل وجود پنل IPS بر روی این صفحه نمایش،  عملکرد آن در زوایای مختلف نیز بسیار مناسب و قابل قبول است. : tensor(0)\n",
            "همکارم این دانگل رو خریده بود و بعد از گذشت حدود 10 روز استفاده میگفت که بسیار دانگل خوبی است. لگ ندارد. افت کیفیت ندارد. برد خوبی دارد در حد 5 متر، خیلی راحت متصل میشود و داغ نمیکند.\r\n",
            "در شگفت انگیز ارزش خرید بالایی دارد. \r\n",
            "دیجی جان شگفت انگیزش کن من و چندتا دوستان میخوایم خرید کنیم. : tensor(0)\n",
            "چقد فاصله داریم!!! : tensor(0)\n",
            "خیلی زود شارژ خالی میکنه : tensor(0)\n",
            "گوشت استفاده شده در غذاها بوی نامطبوع داشت و سفت و ناپخته بود : tensor(0)\n",
            "جديد هم هست : tensor(0)\n",
            "بسیار با کیفیت بود. : tensor(0)\n",
            "با اینکه لنز آن به جای توانایی زوم 6 برابر،  توانایی زوم 5 برابر را دارد،  ولی کمینه‌ی نسبت کانونی لنز W630 در حالت واید فقط f/2.6 می‌باشد که برای عکاسی در شرایط نوری ضعیف عالیست. : tensor(0)\n",
            "وسیله خوبی هست ولی تا بازش کردم جنس پلاستیکش تو ذوقم زد. : tensor(0)\n",
            "زیبا بود . امیدوارم شعر های زیبا تری از ایشون بیرون بیاید . از طاقچه هم بابت رایگان کردنش ممنونم : tensor(0)\n"
          ]
        }
      ],
      "source": [
        "result = pt_model(sample_batch['input_ids'].to(device), \n",
        "                   sample_batch['attention_mask'].to(device),\n",
        "                   sample_batch['token_type_ids'].to(device))\n",
        "\n",
        "# Make Prediction\n",
        "_, predictions = torch.max(result, dim=1)\n",
        "\n",
        "for i, comment in enumerate(sample_batch['comment']):\n",
        "    print(str(comment) + \" : \" + str(predictions[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "w6m3I4wuTqie"
      },
      "outputs": [],
      "source": [
        "def stack_y(y_true, y_pred):\n",
        "    y_true = torch.stack(y_true).cpu().detach().numpy()\n",
        "    y_pred = torch.stack(y_pred).cpu().detach().numpy()\n",
        "    return [y_true, y_pred]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Method"
      ],
      "metadata": {
        "id": "Fw-I3DmoOvjE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "E78X9PjqUi-3"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "gmCBcwACS_En"
      },
      "outputs": [],
      "source": [
        "def train(model, \n",
        "          data_loader, \n",
        "          step=0, \n",
        "          print_every_step=100, \n",
        "          eval_cb=None,\n",
        "          eval_min_loss=np.Inf,\n",
        "          eval_data_loader=None, \n",
        "          clip=0.0):\n",
        "    \n",
        "\n",
        "    # Tell Model that We are training model\n",
        "    model.train()\n",
        "\n",
        "    # Store Losses in each step\n",
        "    losses = []\n",
        "    # Each Step Prediction\n",
        "    y_pred = []\n",
        "    # Each Step True Label\n",
        "    y_true = []\n",
        "\n",
        "    # AdamW Optimizer\n",
        "    optimizer = AdamW(pt_model.parameters(), lr=LEARNING_RATE, correct_bias=False)\n",
        "\n",
        "    # Loss Function\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Total Required Steps\n",
        "    total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "    # Scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0,\n",
        "                                                num_training_steps=total_steps)\n",
        "    \n",
        "    for batch in tqdm(data_loader, total=len(data_loader), desc=\"Training Process \"):\n",
        "        step += 1\n",
        "\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        token_type_ids = batch['token_type_ids']\n",
        "        targets = batch['targets']\n",
        "\n",
        "        # Using CUDA if available\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        token_type_ids = token_type_ids.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Clear previous gradiant optimized variables\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Predict results\n",
        "        results = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids)\n",
        "        \n",
        "        # convert output probabilities to predicted class\n",
        "        _, predictions = torch.max(results, dim=1)\n",
        "\n",
        "        # calculate the batch loss and append it to end of Losses list\n",
        "        loss = loss_fn(results, targets)\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        # Also Append predictions and true labels\n",
        "        y_pred.extend(predictions)\n",
        "        y_true.extend(targets)\n",
        "\n",
        "        # Compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        if clip > 0.0:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "\n",
        "        # perform optimization step\n",
        "        optimizer.step()\n",
        "\n",
        "        # perform scheduler step\n",
        "        scheduler.step()\n",
        "\n",
        "        # Stack True labels and Predictions\n",
        "        train_y = stack_y(y_true, y_pred)\n",
        "\n",
        "        # Calculate Average Loss\n",
        "        train_loss = np.mean(losses)\n",
        "        \n",
        "        if step % print_every_step == 0:\n",
        "            eval_y, eval_loss = evaluation(model, eval_data_loader, loss_fn)\n",
        "            eval_score = acc_and_f1(eval_y[0], eval_y[1], average='weighted')\n",
        "\n",
        "            print('Epoch: {}/{}...'.format(epoch, epochs))\n",
        "            print('Step: {}...'.format(step))\n",
        "            \n",
        "            print('Train Loss: {:.6f}...'.format(train_loss))\n",
        "            print('Train Acc: {:.3f}...'.format(accuracy_score(train_y[0], train_y[1])))\n",
        "\n",
        "            print('Valid Loss: {:.6f}...'.format(eval_loss))\n",
        "            print('Valid Acc: {:.3f}...'.format(accuracy_score(eval_y[0], eval_y[1])))\n",
        "\n",
        "\n",
        "            if eval_loss <= eval_min_loss:\n",
        "                print('Validation Loss Change is : ({:.5f} --> {:.5f}).'.format(eval_loss_min, eval_loss))\n",
        "                eval_min_loss = eval_loss\n",
        "\n",
        "                print(\"Model Saved.\")\n",
        "                torch.save(model.state_dict(), output_path)\n",
        "\n",
        "    # Stack True labels and Predictions\n",
        "    train_y = stack_y(y_true, y_pred)\n",
        "\n",
        "    # Calculate Average Loss\n",
        "    train_loss = np.mean(losses)\n",
        "\n",
        "    return train_y, train_loss, step, eval_min_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Method"
      ],
      "metadata": {
        "id": "-GgFTfcDO0_z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6hS5ztsgTw15"
      },
      "outputs": [],
      "source": [
        "def evaluation(model, data_loader, loss_fn):\n",
        "\n",
        "    # Tell Model that We are evaluating model\n",
        "    model.eval()\n",
        "\n",
        "    # Store Losses in each step\n",
        "    losses = []\n",
        "    # Each Step Prediction\n",
        "    y_pred = []\n",
        "    # Each Step True Label\n",
        "    y_true = []\n",
        "\n",
        "\n",
        "    # Stop Optimizing on evaluation data\n",
        "    with torch.no_grad():\n",
        "        for dl in tqdm(data_loader, total=len(data_loader), desc=\"Evaluation Process\"):\n",
        "            \n",
        "            input_ids = batch['input_ids']\n",
        "            attention_mask = batch['attention_mask']\n",
        "            token_type_ids = batch['token_type_ids']\n",
        "            targets = batch['targets']\n",
        "\n",
        "            # Using CUDA if available\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # Predict results\n",
        "            results = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids)\n",
        "            \n",
        "            # convert output probabilities to predicted class\n",
        "            _, predictions = torch.max(results, dim=1)\n",
        "\n",
        "            # calculate the batch loss and append it to end of Losses list\n",
        "            loss = loss_fn(results, targets)\n",
        "            losses.append(loss.item())\n",
        "            \n",
        "            # Also Append predictions and true labels\n",
        "            y_pred.extend(predictions)\n",
        "            y_true.extend(targets)\n",
        "    \n",
        "    # Stack True labels and Predictions\n",
        "    eval_y = stack_y(y_true, y_pred)\n",
        "\n",
        "    # Calculate Average Loss\n",
        "    eval_loss = np.mean(losses)\n",
        "\n",
        "    return eval_y, eval_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Model"
      ],
      "metadata": {
        "id": "LqP6WGbMFyG7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463,
          "referenced_widgets": [
            "857442431dfc4399a69b47e94210cb6a",
            "6da68a33e6d74917b374eac689895e42",
            "108d28c4cf984bafba4a80b48c7a28e8",
            "5a54abf6d12144858ebc3fc23df9e5a6",
            "e786ae2f1fc540b88abe104a09c196d8",
            "c44aa4456b7e4a509c8e32e5e058e8f6",
            "693f24e0c78246a88079cbab880fc035",
            "17ce7916213d4054bb086697d7fc3be2",
            "5801e536aabd4a60851add523c5df5be",
            "f61f8e5c92474882881bbee30e07b4db",
            "9dbe3e800ceb448fb2565c3f91f60ea1",
            "203503311c6f4a5ca961326fb3f5d76f",
            "af752a3bd02a47fda0d6715fd5aabbbc",
            "cc4687d2c1f44a40837fb8867f05788e",
            "38a49d1ce04545ec99eec4a5c85e3630",
            "5931a38da6ae4bb982b534036f9271e0",
            "2282feabfeca46248e1e6d23beb7011b",
            "537bc26b899447e7a96bf90df4084b87",
            "668da1261d1544818aa466da1b1783e0",
            "d0ab2375b0f54524b24659929b2a91d2",
            "8b995d5fe42c48bbba8ddcb9f2c1069d",
            "f39b99a91e1f4af4b05b3bb36495bfe3"
          ]
        },
        "id": "F2-6ylDNTz5g",
        "outputId": "598d708e-b2cc-40fd-b4d9-656c70262476"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "857442431dfc4399a69b47e94210cb6a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "epochs...:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "203503311c6f4a5ca961326fb3f5d76f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Training Process :   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-4fd108fd39ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0meval_min_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_min_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0meval_data_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         clip=CLIP)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-a2aba317032c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, step, print_every_step, eval_cb, eval_min_loss, eval_data_loader, clip)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Compute gradient of the loss with respect to model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "step = 0\n",
        "eval_min_loss = np.Inf\n",
        "history = collections.defaultdict(list)\n",
        "\n",
        "for epoch in tqdm(range(1, EPOCHS + 1), desc=\"epochs...\"):\n",
        "    train_y, train_loss, step, eval_min_loss = train(\n",
        "        model=pt_model, \n",
        "        data_loader=train_data_loader, \n",
        "        step=step, \n",
        "        print_every_step=EEVERY_EPOCH, \n",
        "        eval_min_loss=eval_min_loss,\n",
        "        eval_data_loader=valid_data_loader, \n",
        "        clip=CLIP)\n",
        "    \n",
        "    history['train_accuracy'].append(accuracy_score(train_y[0], train_y[1]))\n",
        "    history['train_f1'].append(f1_score(train_y[0], train_y[1], average='weighted'))\n",
        "    history['train_loss'].append(train_loss)\n",
        "\n",
        "    eval_y, eval_loss = eval_op(\n",
        "        model=pt_model, \n",
        "        data_loader=valid_data_loader, \n",
        "        loss_fn=loss_fn)\n",
        "    \n",
        "    history['eval_accuracy'].append(accuracy_score(eval_y[0], eval_y[1]))\n",
        "    history['eval_f1'].append(f1_score(eval_y[0], eval_y[1], average='weighted'))\n",
        "    history['eval_loss'].append(eval_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict Method"
      ],
      "metadata": {
        "id": "V-X2P_pPWM4I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcHEi4yYUXxL"
      },
      "outputs": [],
      "source": [
        "def predict(model, comments, tokenizer, max_len=128, batch_size=32):\n",
        "    data_loader = create_data_loader(comments, None, tokenizer, max_len, batch_size)\n",
        "    \n",
        "    # Append predictions into this list\n",
        "    predictions = []\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(data_loader, position=0):\n",
        "            input_ids = batch['input_ids']\n",
        "            attention_mask = batch['attention_mask']\n",
        "            token_type_ids = batch['token_type_ids']\n",
        "\n",
        "            # Using CUDA if available\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            \n",
        "            # Predict results\n",
        "            results = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids)\n",
        "            \n",
        "            # convert output probabilities to predicted class\n",
        "            _, predictions = torch.max(results, dim=1)\n",
        "\n",
        "            predictions.extend(predictions)\n",
        "\n",
        "    predictions = torch.stack(predictions).cpu().detach().numpy()\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict Test Data"
      ],
      "metadata": {
        "id": "0eBIHve0WRbD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "a61819d9e29945c994620dad56798897",
            "906ba9b5bb9f4b3aa06d1b24becba256",
            "169ba7f4a5384bad83f510c38bb46855",
            "77912f2b8c0e47de8dffd2da3eec603e",
            "df4d859c9e744a18903e3274ee961d12",
            "a9be794c2a9f4e91b81a6bf1dc779425",
            "5f02e81f70704b7ca92a92fa1b7abc0a",
            "bd25892f16994c37bbb0c172648ee622",
            "490810d4b7d64d7aa25c969f8261811b",
            "c3d58ac7e14a4201b42d5fbea9d53e5f",
            "0ad46e9931934755be9dd1d5d4741ec2"
          ]
        },
        "id": "EVSiBX8DH4K-",
        "outputId": "307303ed-d4b6-4bf5-ccf9-01d64e27ebf9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a61819d9e29945c994620dad56798897",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(200,) (200, 2)\n"
          ]
        }
      ],
      "source": [
        "test_comments = df_eval['cat_clean_comment'].to_numpy()\n",
        "predictions = predict(pt_model, test_comments, tokenizer, max_len=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy"
      ],
      "metadata": {
        "id": "7Vt4ewpsXUhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy: {}'.format(accuracy_score(test_y, predictions)))"
      ],
      "metadata": {
        "id": "OY4jy9V4XEaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F1-Score"
      ],
      "metadata": {
        "id": "5OF6CMdWW-sI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHpsAqpxIJa5",
        "outputId": "2ab820d0-668a-4e62-db99-00a1cb71c157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1: 0.6673980703392468\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.62      0.56      0.59        85\n",
            "    positive       0.70      0.75      0.72       115\n",
            "\n",
            "    accuracy                           0.67       200\n",
            "   macro avg       0.66      0.66      0.66       200\n",
            "weighted avg       0.67      0.67      0.67       200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f'F1: {}'.format(f1_score(test_y, predictions, average=\"weighted\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification Report"
      ],
      "metadata": {
        "id": "E8dRHZU2W7Tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_y, predictions, target_names=['positive','negative']))"
      ],
      "metadata": {
        "id": "E8lF7TwuW6Yr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ad46e9931934755be9dd1d5d4741ec2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "169ba7f4a5384bad83f510c38bb46855": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f02e81f70704b7ca92a92fa1b7abc0a",
            "placeholder": "​",
            "style": "IPY_MODEL_a9be794c2a9f4e91b81a6bf1dc779425",
            "value": "100%"
          }
        },
        "490810d4b7d64d7aa25c969f8261811b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f02e81f70704b7ca92a92fa1b7abc0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77912f2b8c0e47de8dffd2da3eec603e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_490810d4b7d64d7aa25c969f8261811b",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd25892f16994c37bbb0c172648ee622",
            "value": 7
          }
        },
        "906ba9b5bb9f4b3aa06d1b24becba256": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a61819d9e29945c994620dad56798897": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_169ba7f4a5384bad83f510c38bb46855",
              "IPY_MODEL_77912f2b8c0e47de8dffd2da3eec603e",
              "IPY_MODEL_df4d859c9e744a18903e3274ee961d12"
            ],
            "layout": "IPY_MODEL_906ba9b5bb9f4b3aa06d1b24becba256"
          }
        },
        "a9be794c2a9f4e91b81a6bf1dc779425": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd25892f16994c37bbb0c172648ee622": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3d58ac7e14a4201b42d5fbea9d53e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df4d859c9e744a18903e3274ee961d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ad46e9931934755be9dd1d5d4741ec2",
            "placeholder": "​",
            "style": "IPY_MODEL_c3d58ac7e14a4201b42d5fbea9d53e5f",
            "value": " 7/7 [00:03&lt;00:00,  2.13it/s]"
          }
        },
        "857442431dfc4399a69b47e94210cb6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6da68a33e6d74917b374eac689895e42",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_108d28c4cf984bafba4a80b48c7a28e8",
              "IPY_MODEL_5a54abf6d12144858ebc3fc23df9e5a6",
              "IPY_MODEL_e786ae2f1fc540b88abe104a09c196d8"
            ]
          }
        },
        "6da68a33e6d74917b374eac689895e42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "108d28c4cf984bafba4a80b48c7a28e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c44aa4456b7e4a509c8e32e5e058e8f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "epochs...:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_693f24e0c78246a88079cbab880fc035"
          }
        },
        "5a54abf6d12144858ebc3fc23df9e5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_17ce7916213d4054bb086697d7fc3be2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5801e536aabd4a60851add523c5df5be"
          }
        },
        "e786ae2f1fc540b88abe104a09c196d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f61f8e5c92474882881bbee30e07b4db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/3 [00:57&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9dbe3e800ceb448fb2565c3f91f60ea1"
          }
        },
        "c44aa4456b7e4a509c8e32e5e058e8f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "693f24e0c78246a88079cbab880fc035": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17ce7916213d4054bb086697d7fc3be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5801e536aabd4a60851add523c5df5be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f61f8e5c92474882881bbee30e07b4db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9dbe3e800ceb448fb2565c3f91f60ea1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "203503311c6f4a5ca961326fb3f5d76f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_af752a3bd02a47fda0d6715fd5aabbbc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cc4687d2c1f44a40837fb8867f05788e",
              "IPY_MODEL_38a49d1ce04545ec99eec4a5c85e3630",
              "IPY_MODEL_5931a38da6ae4bb982b534036f9271e0"
            ]
          }
        },
        "af752a3bd02a47fda0d6715fd5aabbbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc4687d2c1f44a40837fb8867f05788e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2282feabfeca46248e1e6d23beb7011b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Training Process :   4%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_537bc26b899447e7a96bf90df4084b87"
          }
        },
        "38a49d1ce04545ec99eec4a5c85e3630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_668da1261d1544818aa466da1b1783e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0ab2375b0f54524b24659929b2a91d2"
          }
        },
        "5931a38da6ae4bb982b534036f9271e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b995d5fe42c48bbba8ddcb9f2c1069d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/50 [00:57&lt;15:52, 19.84s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f39b99a91e1f4af4b05b3bb36495bfe3"
          }
        },
        "2282feabfeca46248e1e6d23beb7011b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "537bc26b899447e7a96bf90df4084b87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "668da1261d1544818aa466da1b1783e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0ab2375b0f54524b24659929b2a91d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b995d5fe42c48bbba8ddcb9f2c1069d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f39b99a91e1f4af4b05b3bb36495bfe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}